### **Hello all!**

Today I want to share with you a bit of my journey getting back into the world of AI. I could start by diving directly into code and model training, but I want to tell a short story first.

### A long time ago, in a distant galaxy‚Ä¶

I started studying AI long ago but had to abandon that pursuit because of circumstances outside my control. Long story short, when I graduated from college in 2019, I had to take on the first job that would accept me. Despite my AI-focused efforts during university, I ended up taking on a front-end engineering role. The good news is that I liked it! However, one front-end engineering job led to a full-stack one, which led to another full-stack one‚Ä¶ and now, after five years or so I'm finally having the chance to go back and explore the world of AI once again.  
The first thing that caught my attention while doing some deep learning work was how much the study resources have evolved. Back in 2015, all I can remember was a very theoretical deep learning book, which by the last time I looked at it back then was half-finished and was the best resource we had to learn about the area. Now I see that makes sense ‚Äî It was Ian Goodfellow's Deep Learning book.  
As a third or fourth-semester Computer Engineering student, that book (and also Pattern Recognition and Machine Learning, by Christopher Bishop) scared me A LOT. I was nowhere near the mathematical abilities needed to fully comprehend either of those texts, so I ended up retreating from my theoretical ML/DL advances.  
Nowadays, I see so many good resources for beginners. I'm currently going through the [Deep Learning for Coders](https://course.fast.ai) course by the Fast.ai folks, and it's been a great experience. As they put it in the first video, things which were jokingly impossible in 2015 are now so accessible I can achieve them on my own laptop, which is amazing. Scrimba‚Äôs AI engineering path is also an excellent resource to learn more about the practical side of things, especially on how to deploy LLM and AI agents as part of a fullstack application (learning React.js and Ruby on Rails came in quite handy after all!)  
Today I want to bring in my version of the classification notebook used as an example for the first class of the Deep Learning for Coders mentioned above. My personal goal for this first project wasn't to achieve a perfect model, far from that, but to get my hands dirty and actually put a DL model into production.

### The somewhat weird path to production

Starting new endeavours is always exciting. It's awesome to get in touch with all these new, shining technologies and make a run with them. One thing that stood out to me as a little bit more difficult than I thought it'd be is deployment. At first, I thought it was cool that both Fast.ai and Scrimba's courses had specific sections on deployment. It seemed to me as nice extra modules. After all, how hard can it be to put a model into production? Getting a standard web application is just a matter of starting a Rails/React application and sending it up to the cloud, maybe getting a Digital Ocean droplet or a Heroku instance.

Boy, was I wrong. I mean ‚Äî it is completely possible that this is my significant lack of experience talking, but there are so many services regarding AI models out there, and there‚Äôs so much overlapping over them that it felt as if I was lost among a thousand options, none of which were quite what I had in mind. I was expecting a simple service, where I'd train a model and it'd be already be automatically deployed to an inference endpoint I could consume from a front-end application.

HuggingFace was the one that closest to it. During the Fast.ai course, they show you how to deploy a Gradio application. It's quite nice, but it doesn't seem to allow a lot of customization, which is not so good for someone wanting to deploy a full fledged ReactJS app. So the thought in my head was ‚Äúwell, no problem, I can probably train a model elsewhere and host it through HuggingFace's Inference API‚Äù. Someone recommended me using Google Colab to run a notebook where I could train said model, and so I did. I copied all the code I had already worked on in Kaggle (which they use during the Fast.ai course) and pasted it into Google collab. Since it involved fetching some images from DuckDuckGo's service, I left the code running while I got some sleep overnight.

If you have any experience developing these things, you‚Äôre probably chuckling at what happened next. I came in the next morning and‚Ä¶ nothing was there. After some research I learned that you can't leave a Colab notebook without interaction for more than 12 hours or it'll disconnect (and lose all your data during the process). The alternative Google gives to not losing that data is by having you connect your Google Drive account and saving it there. It's a decent approach: you're using their GPU services for free, so you should at least take care of your own data. I'm fine with cleaning up some space to do that, but that introduced something I'm quite not a fan of as a programmer: hackish code that's not directly related to what I'm intending to do meant solely to correct the unintuitive behavior of the underlying system. I'd have to take care of saving the model after each epoch, zipping and downloading training data here and there‚Ä¶ it's nothing super complicated but that I'd like to avoid if at all possible.

Therefore, my next step was to try and see if I could grab a computer with a decent GPU where I wouldn't have to worry about that. There‚Äôs quite a few online services that provide this, so I chose the one I felt most comfortable with: [RunPod](https://runpod.io). If you‚Äôre not familiar, they allow you to rent linux instances with powerful GPUs included. I took one of the cheapest On-Demand one, costing $0.32 an hour. It's not much, but it‚Äôs also the kind of thing that can accumulate over time and turn into a huge bill, so I'm trying to use it as efficiently as possible. One of the things that surprised me the most about this is the speed of that cheap GPU. I know - shouldn‚Äôt be too surprising that a paid service will deliver a better experience than a free one, but still. While Colab took a somewhat long time to train my model (I can't remember exactly how long it was, but it was above ten minutes for sure), the RunPod instance took 6 seconds to train each epoque. Talk about a return of investment!

RunPod also allowed me to do a couple more things that I wanted to: Easily download the training data, which is something I couldn't find on a first look in Colab and also connecting to the my cloud machine (which they call a ‚Äúpod‚Äù) through SSH so I could use my local VSCode to work on the code remotely. It does require a bit of a setup, but I have to say they have a couple blog posts ([here](https://blog.runpod.io/how-to-achieve-true-ssh-on-runpod/) and [here](https://blog.runpod.io/accessing-a-runpod-pod-via-ssh-username-password/)) that are helpful.

### Do you like soccer team shirts?

Once I got to actual coding, I was finally able to train my model and see it in action. I decided to stay close to the [example notebook](https://www.kaggle.com/code/jhoward/is-it-a-bird-creating-a-model-from-your-own-data) they hand in the Fast.ai course and build a classifier for soccer team shirts. If you're not a fan of soccer, you've probably still seen a few of the uniforms the teams use. They're either completely different between themselves (think Real Madrid and Barcelona) or they‚Äôre almost each other exact copies (think Newcasttle United and Juventus)

[![juventus vs newcasttle shirts](https://preview.redd.it/which-do-you-prefer-juve-or-toon-adidas-kit-v0-ezk4z8f4mvcd1.jpeg?width=640&crop=smart&auto=webp&s=71ae6431e6f4b4a0b8c26b9aededb83cc6900951 align="center")](https://www.reddit.com/r/NUFC/comments/1e4nnit/which_do_you_prefer_juve_or_toon_adidas_kit/)

In the image above, Juventus is on top and Newcasttle is below. Would you be able to tell which is which without following soccer? I probably wouldn't. So my idea was to build a classifier to try and distinguish soccer shirts from one team to another. I decided to start out with Brazilian teams, because well‚Ä¶ I am Brazilian üòÖ But also, because the team I support, Botafogo (the best one, btw), also has a t-shirt that looks a lot like the ones above:

![Camisa Botafogo Oficial 1 Reebok 2024](https://botafogo.vtexassets.com/arquivos/ids/157971/7908796729583_1.png?v=638501084405470000 align="left")

Could my AI model distinguish between those very alike t-shirts? Let's try and see.

### Finally some code!

I wrote a Jupyter notebook for this exploration. Head over [here](https://github.com/teogenesmoura/soccer_team_classifier/blob/main/soccer_notebook_final.ipynb) to check it out!